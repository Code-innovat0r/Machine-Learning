{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e500bb3-3901-4762-9e81-5a74ddcae828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41736951-8543-4984-b8dc-2a061f522cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('kaggle_movie_review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aeaf051c-7452-4958-80e5-93326296a9b2",
   "metadata": {
    "panel-layout": {
     "height": 538.727294921875,
     "visible": true,
     "width": 100
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4f5f84a-db8f-4451-93d1-2e819752cd91",
   "metadata": {
    "panel-layout": {
     "height": 256.7727355957031,
     "visible": true,
     "width": 100
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['review'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eca9e63f-0964-4f1a-af51-214deacc903a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text cleaning\n",
    "\n",
    "#1. Sample 10000 rows\n",
    "#2. Remove html tags\n",
    "#3. Remove special character\n",
    "#4. Converting everything to lower case\n",
    "#5. Removing stop words (AND, IS,THE, FROM like words)\n",
    "#6. Stemming (play, playing, played are different words but sense is play, so stemming combine such words ans give out play.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2be0f505-bb44-4a65-9974-3fd8deab1ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e533062-aeaf-4c48-9af7-f5d023574bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18f79536-5e02-4106-8ae8-22947ed286f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of                                                   review sentiment\n",
       "11944  This movie is not only boring, it is also real...  negative\n",
       "26521  I saw the movie recently and really liked it. ...  positive\n",
       "42847  i had been looking for this film for so long b...  positive\n",
       "964    I may be a good old boy from Virginia in the C...  positive\n",
       "22356  Jacqueline Susann wrote several novels all inv...  negative\n",
       "...                                                  ...       ...\n",
       "31236  North and South is a miniseries from the \"gold...  positive\n",
       "35229  Acidic, unremitting, and beautiful, John Schle...  positive\n",
       "24743  PUT THE CAMERA ON ME is a deceptively cute fil...  positive\n",
       "4525   Ah, Lucio Fulci, rest in peace. This infamous ...  negative\n",
       "27146  In & Out was a funny comedy with good performa...  positive\n",
       "\n",
       "[10000 rows x 2 columns]>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.info #no missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bfee7e82-17c4-4274-ac38-e468986bedc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace({'sentiment': {'positive': 1, 'negative': 0}},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96d2ba60-60c6-4f37-85f5-92d8d826a5bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                   review  sentiment\n",
       "11944  This movie is not only boring, it is also real...          0\n",
       "26521  I saw the movie recently and really liked it. ...          1\n",
       "42847  i had been looking for this film for so long b...          1\n",
       "964    I may be a good old boy from Virginia in the C...          1\n",
       "22356  Jacqueline Susann wrote several novels all inv...          0\n",
       "...                                                  ...        ...\n",
       "31236  North and South is a miniseries from the \"gold...          1\n",
       "35229  Acidic, unremitting, and beautiful, John Schle...          1\n",
       "24743  PUT THE CAMERA ON ME is a deceptively cute fil...          1\n",
       "4525   Ah, Lucio Fulci, rest in peace. This infamous ...          0\n",
       "27146  In & Out was a funny comedy with good performa...          1\n",
       "\n",
       "[10000 rows x 2 columns]>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a34bd42-2d5f-41fc-8b13-490ec34fa9b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i had been looking for this film for so long before i found it, i had seen it when i was younger and loved it, after my second viewing i still loved it and i still do.this is a love/hate film, if you like bottom, young ones, the comic strip, then you will find this funny. If you don't like that kind of humour then don't bother. I love this film and have grown up with these comedy programmes, for me this film is simply placing their comic genius on the big screen.. It is not an award winner by any means but if you just want good wholesome slapstick then this is it!the film lacks the quality of the TV series and this is usually the case with films but it still has enough material to keep you laughing even if a lot of the jokes are pretty similar to their previous work.yes, the humour is a little childish and not to everyone's taste but sometimes you just need that in a film.\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove all the html tag\n",
    "import re\n",
    "clean = re.compile('<.*?>')\n",
    "# testing the function\n",
    "re.sub(clean, '', data.iloc[2].review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "db3be162-f80d-45ef-9035-a0cd9bb37203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function to remove\n",
    "def clean_html(text):\n",
    "    clean = re.compile('<.*?>')\n",
    "    return re.sub(clean, '' ,text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "351cf39e-8eb6-4c81-85b7-65b09771d31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#passing the review rows to clean\n",
    "data['review'] = data['review'].apply(clean_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e81aa10d-cb3b-4b29-9760-c078e5bde63e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11944    This movie is not only boring, it is also real...\n",
       "26521    I saw the movie recently and really liked it. ...\n",
       "42847    i had been looking for this film for so long b...\n",
       "964      I may be a good old boy from Virginia in the C...\n",
       "22356    Jacqueline Susann wrote several novels all inv...\n",
       "                               ...                        \n",
       "31236    North and South is a miniseries from the \"gold...\n",
       "35229    Acidic, unremitting, and beautiful, John Schle...\n",
       "24743    PUT THE CAMERA ON ME is a deceptively cute fil...\n",
       "4525     Ah, Lucio Fulci, rest in peace. This infamous ...\n",
       "27146    In & Out was a funny comedy with good performa...\n",
       "Name: review, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4569a551-8513-44fb-aaab-41605dd5d917",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# convert to lower case\n",
    "\n",
    "def lower_case(text):\n",
    "    return text.lower()\n",
    "\n",
    "data['review'] = data['review'].apply(lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a534bce3-d814-43f4-9a43-84bba15618e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                   review  sentiment\n",
       "11944  this movie is not only boring, it is also real...          0\n",
       "26521  i saw the movie recently and really liked it. ...          1\n",
       "42847  i had been looking for this film for so long b...          1\n",
       "964    i may be a good old boy from virginia in the c...          1\n",
       "22356  jacqueline susann wrote several novels all inv...          0\n",
       "...                                                  ...        ...\n",
       "31236  north and south is a miniseries from the \"gold...          1\n",
       "35229  acidic, unremitting, and beautiful, john schle...          1\n",
       "24743  put the camera on me is a deceptively cute fil...          1\n",
       "4525   ah, lucio fulci, rest in peace. this infamous ...          0\n",
       "27146  in & out was a funny comedy with good performa...          1\n",
       "\n",
       "[10000 rows x 2 columns]>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "66444b81-4918-423b-9d61-1f95f42ac2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove the special character\n",
    "\n",
    "def remove_speChar(text):\n",
    "    x=''\n",
    "\n",
    "    for i in text:\n",
    "        if i.isalnum():\n",
    "            x = x+i\n",
    "        else:\n",
    "            x = x+' '\n",
    "\n",
    "    return x\n",
    "\n",
    "data['review'] = data['review'].apply(remove_speChar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "af2983a2-18b3-4537-bad8-b23fd05ab0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                   review  sentiment\n",
       "11944  this movie is not only boring  it is also real...          0\n",
       "26521  i saw the movie recently and really liked it  ...          1\n",
       "42847  i had been looking for this film for so long b...          1\n",
       "964    i may be a good old boy from virginia in the c...          1\n",
       "22356  jacqueline susann wrote several novels all inv...          0\n",
       "...                                                  ...        ...\n",
       "31236  north and south is a miniseries from the  gold...          1\n",
       "35229  acidic  unremitting  and beautiful  john schle...          1\n",
       "24743  put the camera on me is a deceptively cute fil...          1\n",
       "4525   ah  lucio fulci  rest in peace  this infamous ...          0\n",
       "27146  in   out was a funny comedy with good performa...          1\n",
       "\n",
       "[10000 rows x 2 columns]>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cb04f75a-b23b-4aec-b563-5677a9b089b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m     x\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y\n\u001b[1;32m---> 17\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(remove_stopword)\n",
      "File \u001b[1;32m~\\New folder\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[0;32m   4918\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4919\u001b[0m         func,\n\u001b[0;32m   4920\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[0;32m   4921\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[0;32m   4922\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   4923\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m-> 4924\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[1;32m~\\New folder\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32m~\\New folder\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[0;32m   1508\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[0;32m   1509\u001b[0m )\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\New folder\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[1;32m~\\New folder\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[59], line 9\u001b[0m, in \u001b[0;36mremove_stopword\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremove_stopword\u001b[39m(text):\n\u001b[0;32m      7\u001b[0m     x \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m text\u001b[38;5;241m.\u001b[39msplit():\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;66;03m# stopwords.words('english') return list of the stopwords in english\u001b[39;00m\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m stopwords\u001b[38;5;241m.\u001b[39mwords(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     12\u001b[0m             x\u001b[38;5;241m.\u001b[39mappend(i)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "# Inorder to remove the stopword we use the nltk(natural language toolkit)\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def remove_stopword(text):\n",
    "    x = []\n",
    "\n",
    "    for i in text.split():\n",
    "        # stopwords.words('english') return list of the stopwords in english\n",
    "        if i not in stopwords.words('english'):\n",
    "            x.append(i)\n",
    "    y = x[:] # x transfer to y\n",
    "    x.clear()\n",
    "    return y\n",
    "\n",
    "data['review'] = data['review'].apply(remove_stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "07115129-4247-42ce-be13-19a3ff7331f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing the stemming in the dataset\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "y=[]\n",
    "def stem_word(text):\n",
    "    for i in text:\n",
    "        y.append(ps.stem(i))\n",
    "    z= y[:]\n",
    "    y.clear()\n",
    "    return z\n",
    "\n",
    "data['review'] = data['review'].apply(stem_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8c0d3221-1ed4-43b4-9178-315cc195e8b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                   review  sentiment\n",
       "11944  [t, h, i, s,  , m, o, v, i, e,  , i, s,  , n, ...          0\n",
       "26521  [i,  , s, a, w,  , t, h, e,  , m, o, v, i, e, ...          1\n",
       "42847  [i,  , h, a, d,  , b, e, e, n,  , l, o, o, k, ...          1\n",
       "964    [i,  , m, a, y,  , b, e,  , a,  , g, o, o, d, ...          1\n",
       "22356  [j, a, c, q, u, e, l, i, n, e,  , s, u, s, a, ...          0\n",
       "...                                                  ...        ...\n",
       "31236  [n, o, r, t, h,  , a, n, d,  , s, o, u, t, h, ...          1\n",
       "35229  [a, c, i, d, i, c,  ,  , u, n, r, e, m, i, t, ...          1\n",
       "24743  [p, u, t,  , t, h, e,  , c, a, m, e, r, a,  , ...          1\n",
       "4525   [a, h,  ,  , l, u, c, i, o,  , f, u, l, c, i, ...          0\n",
       "27146  [i, n,  ,  ,  , o, u, t,  , w, a, s,  , a,  , ...          1\n",
       "\n",
       "[10000 rows x 2 columns]>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0c6d4c57-afe9-4637-9f00-3bfd00bcb06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining the list element to get in the previous form \n",
    "def join_back(text):\n",
    "    return \" \".join(text)\n",
    "\n",
    "data['review'] = data['review'].apply(join_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6f672085-7dd7-4bc2-b8d2-37426195b51d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                   review  sentiment\n",
       "11944  t   h   i   s       m   o   v   i   e       i ...          0\n",
       "26521  i       s   a   w       t   h   e       m   o ...          1\n",
       "42847  i       h   a   d       b   e   e   n       l ...          1\n",
       "964    i       m   a   y       b   e       a       g ...          1\n",
       "22356  j   a   c   q   u   e   l   i   n   e       s ...          0\n",
       "...                                                  ...        ...\n",
       "31236  n   o   r   t   h       a   n   d       s   o ...          1\n",
       "35229  a   c   i   d   i   c           u   n   r   e ...          1\n",
       "24743  p   u   t       t   h   e       c   a   m   e ...          1\n",
       "4525   a   h           l   u   c   i   o       f   u ...          0\n",
       "27146  i   n               o   u   t       w   a   s ...          1\n",
       "\n",
       "[10000 rows x 2 columns]>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d9ba58-59d2-4fc3-ae9f-f33899318b48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b00401-e9bd-433d-9551-48f4c289c8a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "98a114c5-97cb-49bd-8ea6-2fe6bab9d08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training process begains here\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9324930a-033a-454e-8943-c0184fd6338f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mfit_transform(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "File \u001b[1;32m~\\New folder\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\New folder\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1372\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1364\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1365\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1366\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1367\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1368\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1369\u001b[0m             )\n\u001b[0;32m   1370\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1372\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_count_vocab(raw_documents, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfixed_vocabulary_)\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1375\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\New folder\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1278\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1276\u001b[0m     vocabulary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(vocabulary)\n\u001b[0;32m   1277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vocabulary:\n\u001b[1;32m-> 1278\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1279\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mempty vocabulary; perhaps the documents only contain stop words\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1280\u001b[0m         )\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indptr[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax:  \u001b[38;5;66;03m# = 2**31 - 1\u001b[39;00m\n\u001b[0;32m   1283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _IS_32BIT:\n",
      "\u001b[1;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "X = cv.fit_transform(data['review']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd719f74-f29b-4847-9558-0d75e7df54e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "panel-cell-order": [
   "aeaf051c-7452-4958-80e5-93326296a9b2",
   "e4f5f84a-db8f-4451-93d1-2e819752cd91"
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
